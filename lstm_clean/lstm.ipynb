{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762590/762590 [31:40<00:00, 401.25it/s]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Загрузка данных\n",
    "df_Pl = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRKJzXJlQSNew0dxrQ8mFQMhBv_4owvfsF2If1b-rmxMZkR5gabHC4OiaSwt8Ul1Omc8taR27UohSeg/pub?gid=429486365&single=true&output=csv')\n",
    "\n",
    "end_know_date = df_Pl['time'].iloc[-1]\n",
    "\n",
    "end_know_date_index = df_Pl[df_Pl['time'] == end_know_date].index[0] +1\n",
    "\n",
    "nan_indices = df_Pl.index[df_Pl['P_l'].isna()]\n",
    "\n",
    "avg_pl = df_Pl['P_l'].mean()\n",
    "\n",
    "end_date = df_Pl['time'].iloc[-1]\n",
    "\n",
    "future_dates = pd.date_range(start='2023-09-10', end='2024-12-31', freq='5T')  # Измените freq по необходимости\n",
    "\n",
    "future_df = pd.DataFrame({'time': future_dates, 'Scaled_P_l': np.nan})\n",
    "\n",
    "df_Pl = pd.concat([df_Pl, future_df], ignore_index=True)\n",
    "\n",
    "end_future_date = df_Pl['time'].iloc[-1]\n",
    "\n",
    "df_Pl['P_l'].fillna(avg_pl, inplace=True)\n",
    "\n",
    "df_Pl['time'] = pd.to_datetime(df_Pl['time'])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "df_Pl['Scaled_P_l'] = scaler.fit_transform(df_Pl['P_l'].values.reshape(-1, 1))\n",
    "\n",
    "look_back = 300\n",
    "\n",
    "end_date_index = df_Pl[df_Pl['time'] >= end_date].index.min()\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for i in tqdm(range(end_date_index - look_back)):\n",
    "    X.append(df_Pl[['Scaled_P_l', 'time']][i:(i + look_back)].values)\n",
    "    y.append(df_Pl['Scaled_P_l'][i + look_back])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            time           P_l  Scaled_P_l\n",
      "0      2016-06-10 16:50:00+00:00  26441.630000    0.247149\n",
      "1      2016-06-10 16:55:00+00:00  26039.196000    0.243314\n",
      "2      2016-06-10 17:00:00+00:00  21790.632000    0.202823\n",
      "3      2016-06-10 17:05:00+00:00  22824.290000    0.212674\n",
      "4      2016-06-10 17:10:00+00:00  23408.187000    0.218239\n",
      "...                          ...           ...         ...\n",
      "900551 2024-12-30 23:40:00+00:00  27261.640799    0.254965\n",
      "900552 2024-12-30 23:45:00+00:00  27261.640799    0.254965\n",
      "900553 2024-12-30 23:50:00+00:00  27261.640799    0.254965\n",
      "900554 2024-12-30 23:55:00+00:00  27261.640799    0.254965\n",
      "900555 2024-12-31 00:00:00+00:00  27261.640799    0.254965\n",
      "\n",
      "[900556 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_Pl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Input, concatenate, LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "time_scaler = MinMaxScaler()\n",
    "\n",
    "print(end_know_date_index)\n",
    "\n",
    "train_size_percent = 0.95\n",
    "train_size = int(end_know_date_index * train_size_percent)\n",
    "\n",
    "# Проверка, чтобы train_size не превышало индекс end_know_date\n",
    "train_size = min(train_size, end_know_date_index)\n",
    "\n",
    "\n",
    "X_train, X_test = X[0:train_size, :], X[train_size:len(X), :]\n",
    "y_train, y_test = y[0:train_size], y[train_size:len(y)]\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 2))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 2))\n",
    "\n",
    "# Создание входов\n",
    "input_cnn = Input(shape=(X_train.shape[1], 1), name='input_cnn')\n",
    "input_lstm = Input(shape=(X_train.shape[1], 1), name='input_lstm')\n",
    "\n",
    "# Сверточный слой для признака P_l\n",
    "conv1 = Conv1D(filters=32, kernel_size=3, activation='relu')(input_cnn)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "flat1 = Flatten()(pool1)\n",
    "\n",
    "# Вход для времени\n",
    "flat2 = Flatten()(input_lstm)\n",
    "\n",
    "# Объединение выходов сверточного слоя и выходов для времени\n",
    "merged = concatenate([flat1, flat2])\n",
    "\n",
    "dense = Dense(units=50, activation='relu')(merged)\n",
    "\n",
    "output = Dense(units=1, activation='linear')(dense)\n",
    "\n",
    "model = Model(inputs=[input_cnn, input_lstm], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "X_cnn = X_train[:, :, 0:1].astype('float32')\n",
    "\n",
    "X_lstm = np.reshape(X_train[:, :, 1], (X_train.shape[0] * X_train.shape[1], 1))\n",
    "X_lstm = np.vectorize(lambda x: x.timestamp())(X_train[:, :, 1]).astype('float32')\n",
    "X_lstm_scaled = time_scaler.fit_transform(X_lstm)\n",
    "\n",
    "X_lstm = np.reshape(X_lstm_scaled, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "end_know_date_index = df_Pl[df_Pl['time'] == end_know_date].index[0]\n",
    "X_train_cnn = X_cnn[:end_know_date_index]\n",
    "X_train_lstm = X_lstm[:end_know_date_index]\n",
    "y_train = y[:end_know_date_index]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2589/2589 [==============================] - 23s 9ms/step - loss: 0.0011 - val_loss: 3.6574e-04\n",
      "Epoch 2/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 2.4832e-04 - val_loss: 3.9634e-04\n",
      "Epoch 3/25\n",
      "2589/2589 [==============================] - 22s 9ms/step - loss: 2.4136e-04 - val_loss: 4.1598e-04\n",
      "Epoch 4/25\n",
      "2589/2589 [==============================] - 22s 9ms/step - loss: 2.2804e-04 - val_loss: 4.6444e-04\n",
      "Epoch 5/25\n",
      "2589/2589 [==============================] - 23s 9ms/step - loss: 2.2135e-04 - val_loss: 4.1208e-04\n",
      "Epoch 6/25\n",
      "2589/2589 [==============================] - 23s 9ms/step - loss: 2.1756e-04 - val_loss: 2.7698e-04\n",
      "Epoch 7/25\n",
      "2589/2589 [==============================] - 23s 9ms/step - loss: 2.1332e-04 - val_loss: 2.8900e-04\n",
      "Epoch 8/25\n",
      "2589/2589 [==============================] - 22s 9ms/step - loss: 2.1087e-04 - val_loss: 3.5062e-04\n",
      "Epoch 9/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 2.0919e-04 - val_loss: 2.9246e-04\n",
      "Epoch 10/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 2.0886e-04 - val_loss: 2.7254e-04\n",
      "Epoch 11/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 2.0744e-04 - val_loss: 2.7786e-04\n",
      "Epoch 12/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 2.0529e-04 - val_loss: 2.8477e-04\n",
      "Epoch 13/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 2.0479e-04 - val_loss: 2.9580e-04\n",
      "Epoch 14/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 2.0471e-04 - val_loss: 2.7174e-04\n",
      "Epoch 15/25\n",
      "2589/2589 [==============================] - 23s 9ms/step - loss: 2.0279e-04 - val_loss: 2.9289e-04\n",
      "Epoch 16/25\n",
      "2589/2589 [==============================] - 23s 9ms/step - loss: 2.0217e-04 - val_loss: 2.7110e-04\n",
      "Epoch 17/25\n",
      "2589/2589 [==============================] - 22s 9ms/step - loss: 2.0189e-04 - val_loss: 3.6601e-04\n",
      "Epoch 18/25\n",
      "2589/2589 [==============================] - 21s 8ms/step - loss: 2.0147e-04 - val_loss: 3.1078e-04\n",
      "Epoch 19/25\n",
      "2589/2589 [==============================] - 21s 8ms/step - loss: 2.0017e-04 - val_loss: 3.5185e-04\n",
      "Epoch 20/25\n",
      "2589/2589 [==============================] - 21s 8ms/step - loss: 1.9986e-04 - val_loss: 2.9687e-04\n",
      "Epoch 21/25\n",
      "2589/2589 [==============================] - 21s 8ms/step - loss: 1.9983e-04 - val_loss: 2.7262e-04\n",
      "Epoch 22/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 1.9884e-04 - val_loss: 2.7023e-04\n",
      "Epoch 23/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 1.9924e-04 - val_loss: 3.2067e-04\n",
      "Epoch 24/25\n",
      "2589/2589 [==============================] - 21s 8ms/step - loss: 1.9784e-04 - val_loss: 2.8875e-04\n",
      "Epoch 25/25\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 1.9818e-04 - val_loss: 3.0805e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x106e25150>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 25\n",
    "batch_size = 252\n",
    "\n",
    "model.fit([X_train_cnn, X_train_lstm], y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitasavvin/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(r'/Users/nikitasavvin/Desktop/Учеба/Load-Balance/lstm/models/' + f'model_e_{epochs}_bs_{batch_size}.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def predict_consumption(dates_to_predict, model, X_cnn, df_Pl, scaler, look_back):\n",
    "    dates_to_predict = pd.to_datetime(dates_to_predict)\n",
    "\n",
    "    if dates_to_predict.tzinfo is None:\n",
    "        dates_to_predict = dates_to_predict.tz_localize(df_Pl['time'].dt.tz)\n",
    "\n",
    "    X_predict_cnn = []\n",
    "    X_predict_lstm = []\n",
    "    print(X_cnn)\n",
    "    for date in dates_to_predict:\n",
    "        # Получение последних look_back точек для каждой даты\n",
    "        indices = df_Pl[df_Pl['time'] <= date].index[-look_back:]\n",
    "        print(indices)\n",
    "        X_predict_cnn.append(X_cnn[indices])\n",
    "        X_predict_lstm.append(df_Pl[df_Pl['time'] <= date].tail(look_back)[['time']].values)\n",
    "\n",
    "    X_predict_cnn = np.array(X_predict_cnn)\n",
    "    X_predict_lstm = np.array(X_predict_lstm)\n",
    "\n",
    "    X_predict_cnn = np.reshape(X_predict_cnn, (X_predict_cnn.shape[0], X_predict_cnn.shape[1], 1))\n",
    "\n",
    "    # Преобразование времени\n",
    "    X_predict_lstm[:,:,0] = (\n",
    "        (X_predict_lstm[:,:,0].astype('datetime64[ns]').view('int64') -\n",
    "         df_Pl['time'].min().timestamp()) /\n",
    "        (df_Pl['time'].max().timestamp() - df_Pl['time'].min().timestamp())\n",
    "    )\n",
    "\n",
    "    predicted_scaled_values = model.predict([X_predict_cnn.astype('float32'), X_predict_lstm.astype('float32')])\n",
    "\n",
    "    predicted_values = scaler.inverse_transform(predicted_scaled_values)\n",
    "\n",
    "    df_predict = pd.DataFrame({'time': dates_to_predict, 'P_l': predicted_values.flatten()})\n",
    "\n",
    "    return df_predict\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRKJzXJlQSNew0dxrQ8mFQMhBv_4owvfsF2If1b-rmxMZkR5gabHC4OiaSwt8Ul1Omc8taR27UohSeg/pub?gid=429486365&single=true&output=csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762891\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.2471494 ]\n",
      "  [0.24331397]\n",
      "  [0.2028228 ]\n",
      "  ...\n",
      "  [0.21761772]\n",
      "  [0.20887344]\n",
      "  [0.21284482]]\n",
      "\n",
      " [[0.24331397]\n",
      "  [0.2028228 ]\n",
      "  [0.21267413]\n",
      "  ...\n",
      "  [0.20887344]\n",
      "  [0.21284482]\n",
      "  [0.22240874]]\n",
      "\n",
      " [[0.2028228 ]\n",
      "  [0.21267413]\n",
      "  [0.218239  ]\n",
      "  ...\n",
      "  [0.21284482]\n",
      "  [0.22240874]\n",
      "  [0.23093477]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.15074944]\n",
      "  [0.15820615]\n",
      "  [0.16129883]\n",
      "  ...\n",
      "  [0.15923735]\n",
      "  [0.1602905 ]\n",
      "  [0.14811806]]\n",
      "\n",
      " [[0.15820615]\n",
      "  [0.16129883]\n",
      "  [0.1529005 ]\n",
      "  ...\n",
      "  [0.1602905 ]\n",
      "  [0.14811806]\n",
      "  [0.18209448]]\n",
      "\n",
      " [[0.16129883]\n",
      "  [0.1529005 ]\n",
      "  [0.15827191]\n",
      "  ...\n",
      "  [0.14811806]\n",
      "  [0.18209448]\n",
      "  [0.2223058 ]]]\n",
      "Int64Index([761547, 761548, 761549, 761550, 761551, 761552, 761553, 761554,\n",
      "            761555, 761556,\n",
      "            ...\n",
      "            761837, 761838, 761839, 761840, 761841, 761842, 761843, 761844,\n",
      "            761845, 761846],\n",
      "           dtype='int64', length=300)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 761547 is out of bounds for axis 0 with size 724745",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# google_drive_path = '/content/gdrive/MyDrive/'\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# model_path = google_drive_path + f'model_e_{epochs}_bs_{batch_size}.h5'\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# model =  load_model(model_path)\u001B[39;00m\n\u001B[1;32m     11\u001B[0m model \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m---> 13\u001B[0m predicted_df \u001B[38;5;241m=\u001B[39m predict_consumption(dates_to_predict, model, X_cnn, df_Pl, scaler, look_back)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(predicted_df)\n\u001B[1;32m     17\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m14\u001B[39m, \u001B[38;5;241m7\u001B[39m))\n",
      "Cell \u001B[0;32mIn[64], line 14\u001B[0m, in \u001B[0;36mpredict_consumption\u001B[0;34m(dates_to_predict, model, X_cnn, df_Pl, scaler, look_back)\u001B[0m\n\u001B[1;32m     12\u001B[0m     indices \u001B[38;5;241m=\u001B[39m df_Pl[df_Pl[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m date]\u001B[38;5;241m.\u001B[39mindex[\u001B[38;5;241m-\u001B[39mlook_back:]\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(indices)\n\u001B[0;32m---> 14\u001B[0m     X_predict_cnn\u001B[38;5;241m.\u001B[39mappend(X_cnn[indices])\n\u001B[1;32m     15\u001B[0m     X_predict_lstm\u001B[38;5;241m.\u001B[39mappend(df_Pl[df_Pl[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m date]\u001B[38;5;241m.\u001B[39mtail(look_back)[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m     17\u001B[0m X_predict_cnn \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(X_predict_cnn)\n",
      "\u001B[0;31mIndexError\u001B[0m: index 761547 is out of bounds for axis 0 with size 724745"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dates_to_predict = pd.date_range(start='2023-09-08', end='2023-09-13', freq='5T')\n",
    "dates_to_predict = pd.to_datetime(dates_to_predict)\n",
    "\n",
    "# google_drive_path = '/content/gdrive/MyDrive/'\n",
    "# model_path = google_drive_path + f'model_e_{epochs}_bs_{batch_size}.h5'\n",
    "\n",
    "# model =  load_model(model_path)\n",
    "model = model\n",
    "\n",
    "predicted_df = predict_consumption(dates_to_predict, model, X_cnn, df_Pl, scaler, look_back)\n",
    "\n",
    "print(predicted_df)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(predicted_df['time'], predicted_df['P_l'], linewidth=1)\n",
    "plt.title(label=\"Predict\")\n",
    "plt.ylabel(\"P_l Value\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-11 15:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "print(X_predict_cnn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_predict_cnn"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
